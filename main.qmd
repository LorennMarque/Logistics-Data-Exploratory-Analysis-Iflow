---
title: "An√°lisis de Datos"
format: html
editor: visual
toc: true
toc-location: left
number-sections: true
theme: Darkly
---

```{r,warning=FALSE,echo=FALSE, output=FALSE}
# Limpieza de datos
library(tidyverse)
library(dplyr)
library(skimr)
library(lubridate)

# Analisis exploratorio
library(DataExplorer)
library(inspectdf)
library(plotly)
library(viridis)

# Claves de APIs
mapbox_token <- "pk.eyJ1IjoibG9yZW5uem8iLCJhIjoiY20xcHYyd3g2MDk0bTJxb2k4YWZvOHlmcSJ9.r4E2pcTSM89NNHBFSmvKHw"

# Cargamos los datos
data <- read_csv("data/raw_iflow_data.csv", show_col_types = FALSE)
```

# Introducci√≥n

En el marco del **Primer Desaf√≠o Internacional de la Red Latinoamericana de Ciencia de Datos**, este an√°lisis tiene como prop√≥sito abordar un problema pr√°ctico del √°mbito log√≠stico. El proyecto promueve la colaboraci√≥n entre estudiantes de diversas universidades latinoamericanas, fomentando el trabajo en equipo y la toma de decisiones basadas en datos reales.

El **objeto de estudio** es un conjunto de datos proporcionado por **iFlow**, una empresa argentina especializada en log√≠stica integral, con operaciones tanto nacionales como internacionales dentro del MERCOSUR. iFlow se dedica a la gesti√≥n y co-gerencia de cadenas de abastecimiento para sus clientes, buscando optimizar procesos y mejorar la eficiencia operativa.

### Objetivo del an√°lisis

Este an√°lisis tiene como objetivo:

1.  **Comprender y describir** las principales caracter√≠sticas del conjunto de datos, que incluye **27.484 registros de entregas** realizadas en un per√≠odo de tres meses.

2.  **Identificar patrones y tendencias** que permitan obtener insights relevantes sobre las operaciones de iFlow.

3.  **Detectar posibles inconsistencias o errores** en la base de datos, propias de un entorno operativo real, para evaluarlas e integrarlas al an√°lisis.

### Metodolog√≠a y Alcance

Se trabajar√° con informaci√≥n detallada de las entregas, incluyendo aspectos como direcci√≥n, localidad, coordenadas geogr√°ficas, bultos, peso y unidades transportadas, as√≠ como los tiempos de inicio y finalizaci√≥n de cada entrega. A partir de estos datos se buscar√°:

-   Visualizar y analizar la eficiencia operativa.

-   Detectar √°reas de mejora en los procesos log√≠sticos.

-   Proponer soluciones basadas en evidencia que contribuyan a la optimizaci√≥n del servicio.

Este trabajo culminar√° con la presentaci√≥n de los hallazgos y recomendaciones, cuyo objetivo final es fortalecer la capacidad operativa de iFlow, mejorando su eficiencia y calidad de servicio en el entorno competitivo del MERCOSUR.

# An√°lisis

## Limpieza de datos.

La primera etapa de este an√°lisis consisti√≥ en la **limpieza de datos**, un proceso esencial para garantizar la calidad y fiabilidad de los resultados. Dado que la base proporcionada por **iFlow** contiene informaci√≥n real sobre 27.484 entregas realizadas en un per√≠odo de tres meses, nos enfocamos en **identificar problemas comunes** como:

-   **Valores faltantes:** Campos incompletos que podr√≠an afectar el an√°lisis.

-   **Duplicados:** Registros repetidos que distorsionan los resultados.

-   **Inconsistencias:** Errores en el formato o contenido de los datos (por ejemplo, coordenadas geogr√°ficas incorrectas o tiempos de entrega incoherentes).

-   **Outliers:** Valores at√≠picos que requieren evaluaci√≥n para determinar si corresponden a errores o situaciones reales.

Una vez detectados estos problemas, aplicamos las transformaciones necesarias, como la eliminaci√≥n de duplicados, la correcci√≥n de formatos y la imputaci√≥n o exclusi√≥n de valores faltantes seg√∫n el caso. Este proceso de limpieza fue clave para preparar los datos para un an√°lisis exploratorio robusto y la generaci√≥n de insights confiables sobre la operaci√≥n log√≠stica de iFlow.

### Problemas encontrados.

En primer lugar realizamos algunos cambios para **facilitar el trabajo** con los datos.

-   Tratar Columnas innecesarias

    La columna InicioVisitaPlanificado y FinVisitaPlanificado contienen los mismos valores por lo que las unificamos en una nueva columna.

```{r,warning=FALSE,echo=FALSE}

data <- data %>%
  # Nueva columna para almacenar el horario planificado
  
  mutate(visita_planificada = InicioVisitaPlanificado) %>%
  
  # Eliminamos InicioVisitaPlanificado y FinVisitaPlanificado
  
  dplyr::select(-InicioVisitaPlanificado, -FinVisitaPlanificado)
```

-   Formatear correctamente las variables

```{r,warning=FALSE,echo=FALSE}

# Convertir columnas correspondientes a formato de fecha y hora
data$InicioVisitaReal <- as.POSIXct(data$InicioVisitaReal,
                                    format="%Y-%m-%d %H:%M:%OS")

data$FinVisitaReal <- as.POSIXct(data$FinVisitaReal,
                                 format="%Y-%m-%d %H:%M:%OS")

data$visita_planificada <- as.POSIXct(data$visita_planificada,
                                      format="%Y-%m-%d %H:%M:%OS")

# Las columnas InicioHorario1, FinHorario1, las pasamos a caracter para categorizarlas facilmente.
data$InicioHorario1 <- as.character(data$InicioHorario1)
data$FinHorario1 <- as.character(data$FinHorario1)

# Pasamos variables categ√≥ricas a factores.
data$cliente <- as.factor(data$cliente)
```

-   Renombrar las columnas por nombres intuitivos.

```{r ,warning=FALSE,echo=FALSE}
# Renombrar columnas espec√≠ficas con dplyr
data <- data %>%
  rename(      id_orden = iddomicilioorden,
         inicio_horario = InicioHorario1,
            fin_horario = FinHorario1,
                 bultos = Bultos,
                   peso = Peso,
               unidades = Unidades,
          inicio_visita = InicioVisitaReal,
             fin_visita = FinVisitaReal)

# Reorganizar columnas.
data <- data %>%
  dplyr::select(id_orden, cliente, localidad, direccion, latitud, longitud,
         bultos, unidades, peso, inicio_horario, fin_horario, visita_planificada, inicio_visita, fin_visita)
```

Con estos cambios realizados pasamos a modificaciones y **arreglos necesarios** para un an√°lisis correcto de los datos.

-   Eliminaci√≥n de filas duplicadas.

```{r,warning=FALSE,echo=FALSE}
data <- data %>%
  distinct()
```

-   Arreglo de valores faltantes en coordenadas.

    El dato de coordenadas en algunas filas estaba vacio o indicaba "0". En algunos de estos casos pudimos rellenar estas coordenadas con datos existentes del domicilio (21 filas). En caso de que esto no sea posible las filas fueron eliminadas (19 filas) y no ser√°n tomadas en cuenta para el an√°lisis.

```{r,warning=FALSE,echo=FALSE}

# Filtrar las filas donde latitud o longitud son NA
cordenadas_vacias <- data %>%
  filter(
    is.na(latitud) | is.na(longitud) | latitud == 0 | longitud == 0
    )

# cordenadas_vacias # dim 43 x 14

# Filtrar las observaciones donde id_orden est√° en cordenadas_vacias
observaciones_id_orden <- data %>%
  filter(id_orden %in% cordenadas_vacias$id_orden) %>%
  group_by(id_orden) %>%
  summarise(count = n())

# Mostrar el resultado
# observaciones_id_orden

# Contar las apariciones de cada id_orden en cordenadas_vacias
apariciones_cordenadas_vacias <- cordenadas_vacias %>%
  group_by(id_orden) %>%
  summarise(na_count = n())

# Unir las tablas por id_orden
resultado <- observaciones_id_orden %>%
  left_join(apariciones_cordenadas_vacias, by = "id_orden") %>%
  # Si no hay coincidencias en cordenadas_vacias, establecer na_count en 0
  mutate(na_count = ifelse(is.na(na_count), 0, na_count)) %>%
  # Restar las apariciones de cordenadas_vacias del total
  mutate(count_diff = count - na_count) %>%

# Filtrar solo los id_orden donde count_diff es mayor a 0
  filter(count_diff > 0)

# Mostrar el resultado
#resultado
```

```{r,warning=FALSE,echo=FALSE}
# Definir la funci√≥n que revisa y sobrescribe latitud y longitud
reparar_lat_long <- function(dataset, ids) {
  # Iterar sobre cada id de la lista
  for (id in ids) {
    # Filtrar las observaciones v√°lidas de latitud y longitud para este id_orden
    observaciones_validas <- dataset %>%
      filter(id_orden == id & !is.na(latitud) & !is.na(longitud) & latitud != 0 & longitud != 0)
    
    # Si existen observaciones v√°lidas, tomar la primera ocurrencia
    if (nrow(observaciones_validas) > 0) {
      latitud_valida <- observaciones_validas$latitud[1]
      longitud_valida <- observaciones_validas$longitud[1]
      
      # Sobrescribir las observaciones con latitud o longitud nulos o 0
      dataset <- dataset %>%
        mutate(
          latitud = ifelse(id_orden == id & (is.na(latitud) | latitud == 0), latitud_valida, latitud),
          longitud = ifelse(id_orden == id & (is.na(longitud) | longitud == 0), longitud_valida, longitud)
        )
    }
  }
  
  # Retornar el dataset reparado
  return(dataset)
}
```

```{r,warning=FALSE,echo=FALSE}
# Ejecutar la funci√≥n usando los id_orden de la columna resultado
ids_a_reparar <- resultado$id_orden

# Aplicar la funci√≥n a raw_data
data <- reparar_lat_long(data, ids_a_reparar)
```

Por √∫ltimo creamos algunas nuevas columnas para distintos an√°lisis. Entre estas algunas columnas para facilitar la interacci√≥n con fechas y horarios de entregas.

```{r,warning=FALSE,echo=FALSE, output=FALSE}
# Asegurar que los d√≠as se generen en espa√±ol
Sys.setlocale("LC_TIME", "es_ES.UTF-8") 

# Crear la columna 'dia_str' con normalizaci√≥n de caracteres
data <- data %>%
  mutate(
    dia = as.integer(format(fin_visita, "%d")),
    mes = as.integer(format(fin_visita, "%m")),
    hora = as.integer(format(fin_visita, "%H")),
    diferencia_minutos = as.numeric(
      difftime(fin_visita, visita_planificada, units = "mins")),
    dia_str = tolower(iconv(weekdays(fin_visita, abbreviate = FALSE), 
                            to = "UTF-8")),
    duracion_visita_min = as.numeric(
      difftime(fin_visita, inicio_visita, units = "mins")),
    duracion_visita_horas = as.numeric(
      difftime(fin_visita, inicio_visita, units = "hours"))
  )

# Guardamos los datos limpios
# write.csv(x = data, file = "iflow_clean.csv")
```

### Observaciones y sugerencias.

1.  Un gran porcentaje de las entregas tienen registrado el mismo horario para el inicio y final de la visitas.

    Esto puede deberse a la carga apresurada por parte de los repartidores o a un sistema poco eficiente de carga. Podr√≠a solucionarse con mejoras de interfaz o flujo de carga.

```{r,warning=FALSE,echo=FALSE}
data <- read.csv("data/clean_iflow_data.csv")
```

## Detecci√≥n de anomal√≠as.

En esta secci√≥n identificamos situaciones at√≠picas o inesperadas en los datos que podr√≠an influir en la interpretaci√≥n de los resultados. Estas situaciones podr√≠an ser el reflejo de errores operativos, problemas en el registro de datos, o eventos excepcionales en la log√≠stica.

El prop√≥sito de esta etapa fue **registrar y documentar** estas anomal√≠as para analizarlas en mayor profundidad, evaluando si representan errores a corregir o comportamientos relevantes que deben considerarse en la optimizaci√≥n de procesos.

### PENDIENTE Centro de distribuci√≥n en Mendoza.

> mostrar grafico, imagen de google maps y explicaci√≥n¬†

::: panel-tabset
## üìç Mapa

```{r,warning=FALSE,echo=FALSE}
# Crear un gr√°fico usando Plotly y Mapbox
fig <- plot_ly(
  data = data,
  type = 'scattermapbox',
  mode = 'markers',
  lat = ~latitud,
  lon = ~longitud,
  marker = list(size = 8, color = 'blue', opacity = 0.7)
)

# Configurar el estilo de Mapbox (puedes cambiar el estilo)
fig <- fig %>%
  layout(
    mapbox = list(
      style = 'carto-positron', # Otros estilos: 'open-street-map', 'stamen-terrain', etc.
      zoom = 2, # Nivel de zoom
      center = list(lat = mean(data$latitud), lon = mean(data$longitud)) # Centrado en los datos
    ),
    margin = list(t = 0, b = 0, l = 0, r = 0) # Margen para ajustar el espacio del gr√°fico
  )

# Mostrar el gr√°fico
fig

```

##  üñºÔ∏è Screenshot

![](images/screen.png)
:::

### PENDIENTE Entregas en d√≠a domingo.

> mostrar cantidad de entregas por d√≠a, indicar que los domingos no es comun

```{r,warning=FALSE,echo=FALSE}
# Convertir la columna dia_str en un factor ordenado
data <- data %>%
  mutate(dia_str = factor(dia_str, 
                          levels = c("lunes", "martes", "mi√©rcoles", 
                                     "jueves", "viernes", "s√°bado","domingo")))

# Agrupar por el nombre del d√≠a y contar las entregas
entregas_por_dia <- data %>%
  group_by(dia_str) %>%
  summarise(n = n())

# Crear el gr√°fico de barras
ggplot(entregas_por_dia, aes(x = dia_str, y = n)) +
  geom_bar(stat = "identity", fill = "#94C11F") +
  labs(title = "Cantidad de Entregas por D√≠a de la Semana",
       x = "D√≠a de la Semana",
       y = "N√∫mero de Entregas") +
  theme_minimal()
```

> e identificar las entregas con su horario.

### PENDIENTE Entregas consecutivas inmediatas.

Notamos que en las entregas muy cercanas geograficamente, en la misma cuadra, suelen tener el mismo horario de finalizaci√≥n. Esto se puede deber a que los operarios olvidan hacer la carga individual o consideran mas rapido completar ambas entregas antes de registrarlo en el sistema.

Junto con los errores de carga en los horarios de entrega este puede ser un segundo indicador de que el sistema de carga puede ser mejorado para no recolectar datos erroneos en el futuro.

Horarios cargados de forma incorrecta podrian causar:

1.  Mala estimaci√≥n sobre tiempos muertos.
2.  Dificulta optimizar los procesos de entrega.
3.  Perjudica la proyecci√≥n de horarios de entregas o ventanas horarias.

Algunas sugerencias e ideas para mejorar esto incluyen:

-   Mejoras de la interfaz en el sistema de carga para facilitar y fomentar su uso.

-   Implementaci√≥n de un sistema de validaci√≥n de los datos para evitar duplicados.

-   Desarrollo y uso de hardware espec√≠fico para la carga de datos.

## PENDIENTE Vista general.

En esta secci√≥n ofrecemos una **visi√≥n superficial de los datos**, brindando un panorama inicial que permite familiarizarnos con su estructura y contenido.

![](images/clipboard-2661057119.png)

Este primer acercamiento busca proporcionar **intuici√≥n inicial** sobre los patrones m√°s evidentes y √°reas de inter√©s para an√°lisis m√°s profundos.

> Cuantas entregas tenemos en total?

```{r,warning=FALSE,echo=FALSE, output=FALSE}
dim(data)
dim(data %>% filter(cliente==20))
dim(data %>% filter(cliente==70))
```

Hay 27419 entregas, 16545 del cliente 20 y 10874 del cliente 70.

> En que plazo estamos hablando, fecha de la primera entrega y la √∫ltima?

```{r,warning=FALSE,echo=FALSE, output=FALSE}
# Ensure fin_visita is in the correct POSIXct format
data$fin_visita <- as.POSIXct(data$fin_visita, format = "%Y-%m-%d %H:%M:%OS")

# Filter the row with the maximum fin_visita
data %>% 
  filter(fin_visita == min(fin_visita, na.rm = TRUE))

data %>% 
  filter(fin_visita == max(fin_visita, na.rm = TRUE))

```

Primera visita en 2024-05-03 08:08:53. El 3 de Mayo.

√öltima visita en 2024-08-06 16:57:00. El 8 de Agosto.

```{r,warning=FALSE,echo=FALSE}

# Crear una columna con el primer d√≠a del mes correspondiente
data <- data %>%
  mutate(mes = as.Date(floor_date(fin_visita, "month")))  # Asegurar que 'mes' sea Date

# Agrupar por mes y contar la cantidad de entregas
entregas_por_mes <- data %>%
  group_by(mes) %>%
  summarise(n = n())

# Crear el gr√°fico de barras
ggplot(entregas_por_mes, aes(x = mes, y = n)) +
  geom_bar(stat = "identity", fill = "#94C11F") +
  scale_x_date(date_labels = "%b %Y", date_breaks = "1 month") +
  labs(title = "Cantidad de Entregas por Mes",
       x = "Mes",
       y = "N√∫mero de Entregas") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

> ¬øCu√°l es el promedio de bultos, peso y unidades entregadas por pedido?

En promedio cada entrega tiene:

-   28.40 Unidades

-   5.75 Bultos

-   Un peso de 41.15kg

::: panel-tabset
## üî¢ Unidades

```{r,warning=FALSE,echo=FALSE}
# Crear el histograma
ggplot(data, aes(x = unidades)) +
  geom_histogram(binwidth = 50, fill = "#94C11F", color = "black") +
  labs(title = "Histograma de Unidades",
       x = "Bultos",
       y = "Frecuencia") +
  theme_minimal()
```

```{r,warning=FALSE,echo=FALSE}
mean(data$unidades) # Promedio
```

## üì¶ Bultos

```{r,warning=FALSE,echo=FALSE}
# Crear el histograma
ggplot(data, aes(x = bultos)) +
  geom_histogram(binwidth = 5, fill = "#94C11F", color = "black") +
  labs(title = "Histograma de Bultos",
       x = "Unidades",
       y = "Frecuencia") +
  theme_minimal()
```

```{r,warning=FALSE,echo=FALSE}
mean(data$bultos) # Promedio
```

## ‚öñÔ∏è Peso

```{r,warning=FALSE,echo=FALSE}
# Crear el histograma
ggplot(data, aes(x = peso)) +
  geom_histogram(binwidth = 50, fill = "#94C11F", color = "black") +
  labs(title = "Histograma de Peso",
       x = "Unidades",
       y = "Frecuencia") +
  theme_minimal()
```

```{r,warning=FALSE,echo=FALSE}
mean(data$peso) # Promedio
```
:::

> ¬øCu√°l es la distribuci√≥n de entregas por localidad o regi√≥n?

```{r,echo=FALSE, output=FALSE}
# Geolocalizaci√≥n
library(sf)
library(raster)
```

::: panel-tabset
## üèòÔ∏è Barrios

```{r,warning=FALSE,echo=FALSE}
# Cargar los barrios desde el archivo GeoJSON
barrios.comp <- st_read("maps/barrios.geojson")  # Reemplaza con la ruta correcta
  
barrios <- barrios.comp[, c("BARRIO", "geometry")]

# Ver los nombres de las columnas del GeoDataFrame de barrios
# Filtrar las entregas con coordenadas v√°lidas y crear un objeto sf
data_sf <- data %>%
  filter(!is.na(latitud) & !is.na(longitud)) %>%
  st_as_sf(coords = c("longitud", "latitud"), crs = 4326)  # Sistema de coordenadas WGS 84

# Unir cada entrega con su barrio correspondiente
entregas_por_barrio <- st_join(data_sf, barrios)

# Agrupar por el campo "BARRIO" y contar el total de entregas
entregas_agrupadas <- entregas_por_barrio %>%
  group_by(BARRIO) %>%
  summarise(total_entregas = n())

# Unir la informaci√≥n agregada de entregas al GeoDataFrame de barrios
barrios <- barrios %>%
  st_join(entregas_agrupadas)

# Rellenar valores NA (barrios sin entregas) con 0
barrios$total_entregas[is.na(barrios$total_entregas)] <- 0

# Crear el mapa con ggplot2
ggplot(data = barrios) +
  geom_sf(aes(fill = total_entregas)) +  # Colorear seg√∫n la cantidad de entregas
  scale_fill_viridis_c(option = "plasma", na.value = "white") +  # Paleta de colores
  theme_minimal() +
  labs(
    title = "Cantidad de Entregas por Barrio en Buenos Aires",
    fill = "Entregas"
  )
```

## üèôÔ∏è Comunas

```{r, warning=FALSE, echo=FALSE}
# 1. Cargar los barrios desde el archivo GeoJSON
barrios.comp <- st_read("maps/barrios.geojson")  # Ajusta la ruta seg√∫n corresponda

# 2. Agrupar los pol√≠gonos por "COMUNA"
comunas <- barrios.comp %>%
  group_by(COMUNA) %>%
  summarise(geometry = st_union(geometry))  # Unir los pol√≠gonos por comuna

# Asegurarse de que COMUNA sea texto
comunas$COMUNA <- as.character(comunas$COMUNA)

# 3. Filtrar las entregas con coordenadas v√°lidas y convertirlas a un objeto sf
data_sf <- data %>%
  filter(!is.na(latitud) & !is.na(longitud)) %>%
  st_as_sf(coords = c("longitud", "latitud"), crs = 4326)

# 4. Asignar cada entrega a su comuna correspondiente usando st_join
entregas_por_comuna <- st_join(data_sf, comunas)

# 5. Agrupar por "COMUNA" y contar el total de entregas
entregas_agrupadas <- entregas_por_comuna %>%
  group_by(COMUNA) %>%
  summarise(total_entregas = n())

# 6. Unir los datos de entregas agregados al GeoDataFrame de comunas
comunas <- comunas %>%
  st_join(entregas_agrupadas)

# 7. Rellenar los valores NA (comunas sin entregas) con 0
comunas$total_entregas[is.na(comunas$total_entregas)] <- 0

# 8. Crear el mapa con ggplot2
ggplot(data = comunas) +
  geom_sf(aes(fill = total_entregas)) +
  scale_fill_viridis_c(option = "plasma", na.value = "white") +
  theme_minimal() +
  labs(
    title = "Cantidad de Entregas por Comuna en Buenos Aires",
    fill = "Entregas"
  )


```

## üå°Ô∏è Entregas Individuales

```{r, warning=FALSE, echo=FALSE}
# Mapa de calor de entregas
heatmap_data <- data %>%
  group_by(latitud, longitud) %>%
  summarise(total_entregas = n())

# Graficar un mapa de calor para visualizar las zonas con mayor densidad de entregas
heatmap_plot <- plot_ly(
  heatmap_data,
  lat = ~latitud,
  lon = ~longitud,
  z = ~total_entregas,
  type = 'densitymapbox',
  colorscale = 'Viridis',
  radius = 10
) %>%
  layout(
    mapbox = list(
      accesstoken = mapbox_token,
      center = list(lat = -34.6037, lon = -58.3816),
      zoom = 10,
      style = "open-street-map"
    ),
    title = "Mapa de Calor de Entregas en Buenos Aires",
    showlegend = FALSE,  # Ocultar la leyenda
    margin = list(r = 0, t = 60, b = 0, l = 0)  # Agregar m√°s espacio en la parte superior
  )

# Mostrar el mapa de calor
heatmap_plot

```
:::

> ¬øCu√°l es el tiempo promedio entre el inicio y fin de las visitas de entrega?
>
> ¬øExisten picos de entregas en ciertos d√≠as u horas?
>
> ¬øCu√°ntas entregas se hicieron fuera del tiempo esperado o planificado?
>
> ¬øQu√© clientes generan m√°s volumen de entregas y cu√°les presentan m√°s problemas o irregularidades?

## Segmentaci√≥n y patrones en entregas.

### PENDIENTE Volumen y Distribuci√≥n de Entregas

> ¬øCu√°ntas entregas corresponden a cada cliente?
>
> Identificar entregas recurrentes a domicilios, zonas de entregas.
>
> Los domicilios reciben entregas de un √∫nico cliente o solo 20 o 70?
>
> ¬øQu√© porcentaje de entregas se concentra en las localidades m√°s activas?

### PENDIENTE Estacionalidad y temporalidad.

> ¬øQu√© d√≠as de la semana o meses tienen m√°s visitas?
>
> ¬øExisten patrones estacionales en la demanda de entregas (meses con mayor/menor volumen)?
>
> ¬øEl volumen de entregas var√≠a significativamente entre diferentes meses del a√±o?
>
> ¬øC√≥mo var√≠a la demanda entre diferentes semanas o meses?

### PENDIENTE Eficiencia y Rendimiento Operativo

> ¬øCu√°l es el tiempo promedio de entrega por cliente y por localidad?
>
> ¬øQu√© zonas presentan mayores retrasos o entregas fuera de tiempo?
>
> > Identifica √°reas con posibles cuellos de botella log√≠sticos.
>
> ¬øSe detectan diferencias significativas en los tiempos de entrega seg√∫n la cantidad de bultos o peso?

## Distribuci√≥n de entregas

### PENDIENTE Volumen y Cobertura Geogr√°fica

> ¬øCu√°ntas entregas se realizaron en cada localidad o regi√≥n?
>
> ¬øQu√© porcentaje del total de entregas corresponde a las principales localidades?
>
> ¬øQu√© clientes concentran el mayor volumen de entregas en cada regi√≥n?

### PENDIENTE Patrones Temporales por Regi√≥n

> ¬øQu√© d√≠as de la semana tienen mayor volumen de entregas en cada localidad?
>
> ¬øExisten picos de entregas en determinadas horas del d√≠a seg√∫n la regi√≥n?
>
> ¬øC√≥mo var√≠a el volumen de entregas entre diferentes meses o semanas en cada regi√≥n?

### PENDIENTE Eficiencia Operativa por Zona

> ¬øCu√°les son las rutas o regiones con mayor concentraci√≥n de entregas por cliente?
>
> ¬øQu√© localidades presentan mayores retrasos en las entregas?
>
> ¬øC√≥mo afecta la distancia al centro de distribuci√≥n en los tiempos de entrega?
>
> ¬øQu√© impacto tienen las condiciones geogr√°ficas (latitud y longitud) en los tiempos de entrega?
>
> Detecta si la ubicaci√≥n geogr√°fica influye en el rendimiento log√≠stico.

### PENDIENTE Optimizaci√≥n y Recursos

> ¬øC√≥mo var√≠a la densidad de entregas por zona y qu√© impacto tiene en la asignaci√≥n de recursos?
>
> ¬øQu√© zonas podr√≠an beneficiarse de una mayor frecuencia de entregas para mejorar la eficiencia?
>
> ¬øExisten patrones geogr√°ficos en los pedidos con anomal√≠as o entregas fallidas?

## Unidades de Transporte

En los datos proporcionados no contamos con la informaci√≥n necesaria para realizar un an√°lisis espec√≠fico de las unidades de transporte, ya que ser√≠a indispensable disponer de un identificador √∫nico para cada veh√≠culo. Sin embargo, incluimos esta secci√≥n como prueba de concepto para demostrar el valor que podr√≠a generar este tipo de an√°lisis en la operaci√≥n log√≠stica. Disponer de esta informaci√≥n permitir√≠a evaluar aspectos fundamentales de la gesti√≥n de la flota, optimizaci√≥n de rutas y eficiencia operativa.

A continuaci√≥n, presentamos algunas preguntas clave que podr√≠an responderse con un an√°lisis detallado de las unidades de transporte:

#### **Preguntas sobre Desempe√±o y Utilizaci√≥n de la Flota**

1.  **¬øCu√°nto tiempo real dedica cada unidad a entregas versus tiempo muerto (espera, carga, mantenimiento)?**

2.  **¬øCu√°les son los tiempos de ruta promedio por cami√≥n y c√≥mo var√≠an seg√∫n la regi√≥n?**

3.  **¬øEs necesaria la cantidad actual de camiones, o existe capacidad ociosa que podr√≠a aprovecharse?**

4.  **¬øHay rutas o zonas espec√≠ficas donde ser√≠a m√°s eficiente reducir o ampliar la flota?**

5.  **¬øQu√© porcentaje de las unidades completan sus rutas dentro de los tiempos planificados?**

#### **Preguntas sobre Optimizaci√≥n de Rutas y Rendimiento**

6.  **¬øSe podr√≠an consolidar entregas para reducir la cantidad de viajes sin afectar el servicio?**

7.  **¬øExisten unidades con rutas ineficientes que podr√≠an optimizarse con ajustes?**

8.  **¬øCu√°l es la relaci√≥n entre la distancia recorrida y el volumen entregado por unidad?**

9.  **¬øSe podr√≠an reducir tiempos muertos al mejorar la planificaci√≥n de entregas o las ventanas horarias?**

Si bien no contamos con la informaci√≥n completa sobre las unidades de transporte, hemos realizado estimaciones basadas en los datos disponibles y presentamos nuestro an√°lisis como aproximaci√≥n para obtener insights relevantes.

> Ver las sedes de Iflow (que conocemos)
>
> Graficar la primera entrega de cada d√≠a. Graficar la primera y segunda entrega de cada d√≠a. Esperariamos que estas entregas rodeen cada sede. Entender su comportamiento.
>
> Graficar la primera y √∫ltima entrega del d√≠a. (Aclarar que no es la de un camion en particular)
>
> Grafico de orden de las entregas de un d√≠a en espec√≠fico. Conclusiones:
>
> -   Parece que los camiones no mezclan productos del cliente 20 y 70.
>
> -   Tiempos muertos, identificar trayectorias por distancia.
>
> -   Errores de carga cuando hay localidades consecutivas.
>
> Grafico de trayectoria en orden para cada cliente. Identificar puntos que demuestran rutas poco eficientes. Cruces de lineas, tiempo perdido.
>
> Graficar tiempo entre entregas por hora del d√≠a. (Tiempo muerto)
>
> Ampliar u organizar nuevos centros de distribuci√≥n. (En base a los datos de estos dos clientes), Segmentaci√≥n de entregas (global y por cliente) para identificar puntos donde ser√≠a ideal. (Centro de zona, cruce de zonas, cluster con m√°s o menor actividad)

# Conclusiones

# Ap√©ndice
